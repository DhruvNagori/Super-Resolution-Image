{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing baboon.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           22.29       384.10       0.6734\n",
      "Reconstructed Image:      23.04       323.18       0.7675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2017b555cc342e1a4bc2583b6c7f9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing baboon.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "Error processing baboon.bmp: Layer count mismatch when loading weights from file. Model expected 5 layers, found 3 saved layers.\n",
      "\n",
      "Processing baby_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           34.26        24.38       0.9396\n",
      "Reconstructed Image:      36.27        15.36       0.9613\n",
      "Saved to: output/baby_GT_output.png\n",
      "\n",
      "Processing barbara.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           25.89       167.51       0.8183\n",
      "Reconstructed Image:      26.58       142.90       0.8684\n",
      "Saved to: output/barbara_output.png\n",
      "\n",
      "Processing bird_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           32.98        32.74       0.9593\n",
      "Reconstructed Image:      36.56        14.37       0.9846\n",
      "Saved to: output/bird_GT_output.png\n",
      "\n",
      "Processing bridge.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           25.95       165.27       0.7822\n",
      "Reconstructed Image:      27.47       116.32       0.8566\n",
      "Saved to: output/bridge_output.png\n",
      "\n",
      "Processing butterfly_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           24.74       218.17       0.8897\n",
      "Reconstructed Image:      30.37        59.67       0.9590\n",
      "Saved to: output/butterfly_GT_output.png\n",
      "\n",
      "Processing coastguard.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.37       119.19       0.7534\n",
      "Reconstructed Image:      28.68        88.15       0.8302\n",
      "Saved to: output/coastguard_output.png\n",
      "\n",
      "Processing comic.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           23.65       280.80       0.8325\n",
      "Reconstructed Image:      25.89       167.37       0.9110\n",
      "Saved to: output/comic_output.png\n",
      "\n",
      "Processing face.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.89        52.96       0.8421\n",
      "Reconstructed Image:      31.65        44.46       0.8737\n",
      "Saved to: output/face_output.png\n",
      "\n",
      "Processing flowers.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.25       122.36       0.8747\n",
      "Reconstructed Image:      29.67        70.22       0.9300\n",
      "Saved to: output/flowers_output.png\n",
      "\n",
      "Processing foreman.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           32.02        40.86       0.9390\n",
      "Reconstructed Image:      36.08        16.05       0.9653\n",
      "Saved to: output/foreman_output.png\n",
      "\n",
      "Processing head_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.92        52.56       0.8424\n",
      "Reconstructed Image:      31.68        44.16       0.8738\n",
      "Saved to: output/head_GT_output.png\n",
      "\n",
      "Processing lenna.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           31.36        47.50       0.8891\n",
      "Reconstructed Image:      33.11        31.76       0.9171\n",
      "Saved to: output/lenna_output.png\n",
      "\n",
      "Processing man.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.15       125.41       0.8208\n",
      "Reconstructed Image:      29.20        78.10       0.8768\n",
      "Saved to: output/man_output.png\n",
      "\n",
      "Processing monarch.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.05        64.29       0.9466\n",
      "Reconstructed Image:      35.14        19.92       0.9712\n",
      "Saved to: output/monarch_output.png\n",
      "\n",
      "Processing pepper.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           31.45        46.57       0.8881\n",
      "Reconstructed Image:      32.78        34.25       0.9086\n",
      "Saved to: output/pepper_output.png\n",
      "\n",
      "Processing ppt3.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           24.66       222.32       0.9296\n",
      "Reconstructed Image:      27.15       125.30       0.9561\n",
      "Saved to: output/ppt3_output.png\n",
      "\n",
      "Processing woman_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           29.37        75.11       0.9349\n",
      "Reconstructed Image:      33.63        28.18       0.9677\n",
      "Saved to: output/woman_GT_output.png\n",
      "\n",
      "Processing zebra.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.78       108.36       0.8896\n",
      "Reconstructed Image:      30.41        59.16       0.9324\n",
      "Saved to: output/zebra_output.png\n",
      "\n",
      "Generated comprehensive quality report in output/quality_report.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAvgPool2D, Dense, Multiply, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from ipywidgets import interact, IntSlider  # For interactive comparison\n",
    "import pandas as pd  # For quality report\n",
    "import seaborn as sns  # For better visualizations\n",
    "\n",
    "def generate_quality_report(image_names, all_scores):\n",
    "    \"\"\"Generate comprehensive quality report\"\"\"\n",
    "    # Create DataFrame for metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Image': image_names,\n",
    "        'PSNR_Degraded': [s[0][0] for s in all_scores],\n",
    "        'PSNR_Enhanced': [s[1][0] for s in all_scores],\n",
    "        'MSE_Degraded': [s[0][1] for s in all_scores],\n",
    "        'MSE_Enhanced': [s[1][1] for s in all_scores],\n",
    "        'SSIM_Degraded': [s[0][2] for s in all_scores],\n",
    "        'SSIM_Enhanced': [s[1][2] for s in all_scores]\n",
    "    })\n",
    "    \n",
    "    # Calculate improvements\n",
    "    metrics_df['PSNR_Improvement'] = metrics_df['PSNR_Enhanced'] - metrics_df['PSNR_Degraded']\n",
    "    metrics_df['MSE_Reduction'] = metrics_df['MSE_Degraded'] - metrics_df['MSE_Enhanced']\n",
    "    metrics_df['SSIM_Improvement'] = metrics_df['SSIM_Enhanced'] - metrics_df['SSIM_Degraded']\n",
    "    \n",
    "    # Save to CSV\n",
    "    metrics_df.to_csv('output/quality_metrics.csv', index=False)\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(231)\n",
    "    sns.barplot(x='Image', y='PSNR_Improvement', data=metrics_df)\n",
    "    plt.title('PSNR Improvement')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(232)\n",
    "    sns.barplot(x='Image', y='MSE_Reduction', data=metrics_df)\n",
    "    plt.title('MSE Reduction')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(233)\n",
    "    sns.barplot(x='Image', y='SSIM_Improvement', data=metrics_df)\n",
    "    plt.title('SSIM Improvement')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/quality_report.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "def interactive_comparison(original, degraded, enhanced):\n",
    "    \"\"\"Create interactive image comparison\"\"\"\n",
    "    def display_images(alpha=0.5):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Original')\n",
    "        \n",
    "        plt.subplot(132)\n",
    "        plt.imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Degraded')\n",
    "        \n",
    "        plt.subplot(133)\n",
    "        blended = cv2.addWeighted(degraded, 1-alpha, enhanced, alpha, 0)\n",
    "        plt.imshow(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Enhanced (Blend: {alpha:.1f})')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    interact(display_images, alpha=IntSlider(min=0, max=10, step=1, value=5))\n",
    "\n",
    "def compare_architectures(image_path):\n",
    "    \"\"\"Compare different model architectures\"\"\"\n",
    "    architectures = {\n",
    "        'SRCNN': build_model(with_attention=False),\n",
    "        'SRCNN+Attention': build_model(with_attention=True)\n",
    "        # Add more architectures as needed\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in architectures.items():\n",
    "        model.load_weights('3051crop_weight_200.h5')\n",
    "        _, _, output, scores = predict(image_path, use_attention='Attention' in name)\n",
    "        results[name] = {\n",
    "            'output': output,\n",
    "            'scores': scores[1]  # Reconstructed scores only\n",
    "        }\n",
    "    \n",
    "    # Display comparison\n",
    "    print(\"\\nArchitecture Comparison:\")\n",
    "    print(\"{:<20} {:>10} {:>12} {:>12}\".format('Model', 'PSNR (dB)', 'MSE', 'SSIM'))\n",
    "    print(\"-\" * 50)\n",
    "    for name, result in results.items():\n",
    "        print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format(name, *result['scores']))\n",
    "    \n",
    "    # Visual comparison\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, (name, result) in enumerate(results.items(), 1):\n",
    "        plt.subplot(1, len(architectures), i)\n",
    "        plt.imshow(cv2.cvtColor(result['output'], cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"{name}\\nPSNR: {result['scores'][0]:.2f} dB\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    \"\"\"Calculate image quality metrics\"\"\"\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    return [\n",
    "        psnr(img1, img2),\n",
    "        mse(img1, img2),\n",
    "        ssim(img1_gray, img2_gray, multichannel=True)\n",
    "    ]\n",
    "\n",
    "def attention_block(input_tensor):\n",
    "    \"\"\"Channel attention mechanism\"\"\"\n",
    "    channels = input_tensor.shape[-1]\n",
    "    gap = GlobalAvgPool2D()(input_tensor)\n",
    "    fc1 = Dense(channels//8, activation='relu')(gap)\n",
    "    fc2 = Dense(channels, activation='sigmoid')(fc1)\n",
    "    attention = Reshape((1, 1, channels))(fc2)\n",
    "    return Multiply()([input_tensor, attention])\n",
    "\n",
    "def build_model(with_attention=True):\n",
    "    \"\"\"Build SRCNN with optional attention\"\"\"\n",
    "    if with_attention:\n",
    "        inputs = tf.keras.Input(shape=(None, None, 1))\n",
    "        x = Conv2D(128, (9,9), activation='relu', padding='valid')(inputs)\n",
    "        x = attention_block(x)\n",
    "        x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "        outputs = Conv2D(1, (5,5), activation='linear', padding='valid')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Conv2D(128, (9,9), activation='relu', padding='valid', input_shape=(None,None,1)),\n",
    "            Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "            Conv2D(1, (5,5), activation='linear', padding='valid')\n",
    "        ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0003),\n",
    "                 loss='mean_squared_error',\n",
    "                 metrics=['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "def modcrop(img, scale):\n",
    "    \"\"\"Crop image to make dimensions divisible by scale\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    h = h - h % scale\n",
    "    w = w - w % scale\n",
    "    return img[:h, :w]\n",
    "\n",
    "def shave(image, border):\n",
    "    \"\"\"Remove border pixels\"\"\"\n",
    "    return image[border:-border, border:-border]\n",
    "\n",
    "def predict(image_path, use_attention=False):\n",
    "    \"\"\"Super-resolve an image with error handling\"\"\"\n",
    "    try:\n",
    "        srcnn = build_model(with_attention=use_attention)\n",
    "        weights_path = '3051crop_weight_200.h5'\n",
    "        srcnn.load_weights(weights_path)\n",
    "        \n",
    "        degraded = cv2.imread(image_path)\n",
    "        ref_path = os.path.join('source', os.path.basename(image_path))\n",
    "        ref = cv2.imread(ref_path)\n",
    "        \n",
    "        ref = modcrop(ref, 3)\n",
    "        degraded = modcrop(degraded, 3)\n",
    "        \n",
    "        ycrcb = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)\n",
    "        Y = np.zeros((1, *ycrcb.shape[:2], 1), dtype=np.float32)\n",
    "        Y[0, :, :, 0] = ycrcb[:, :, 0].astype(np.float32) / 255.0\n",
    "        \n",
    "        print(f\"\\nProcessing {os.path.basename(image_path)}\")\n",
    "        pre = srcnn.predict(Y, verbose=1)[0] * 255\n",
    "        pre = np.clip(pre, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        temp = shave(ycrcb, 6)\n",
    "        temp[:, :, 0] = pre[:, :, 0]\n",
    "        output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR)\n",
    "        \n",
    "        ref = shave(ref, 6)\n",
    "        degraded = shave(degraded, 6)\n",
    "        \n",
    "        return ref, degraded, output, [\n",
    "            compare_images(degraded, ref),\n",
    "            compare_images(output, ref)\n",
    "        ]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "# Main processing loop\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "all_scores = []\n",
    "image_names = []\n",
    "\n",
    "for file in sorted(f for f in os.listdir('images') if f.lower().endswith('.bmp')):\n",
    "    try:\n",
    "        ref, degraded, output, scores = predict(os.path.join('images', file), use_attention=False)\n",
    "        \n",
    "        if ref is None or degraded is None or output is None:\n",
    "            continue\n",
    "            \n",
    "        # Store results for final report\n",
    "        all_scores.append(scores)\n",
    "        image_names.append(os.path.splitext(file)[0])\n",
    "            \n",
    "        # Display metrics\n",
    "        print(\"\\n{:<20} {:>10} {:>12} {:>12}\".format('', 'PSNR (dB)', 'MSE', 'SSIM'))\n",
    "        print(\"-\" * 50)\n",
    "        print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Degraded Image:', *scores[0]))\n",
    "        print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Reconstructed Image:', *scores[1]))\n",
    "        \n",
    "        # Interactive comparison for the first image\n",
    "        if file == sorted(f for f in os.listdir('images') if f.lower().endswith('.bmp'))[0]:\n",
    "            interactive_comparison(ref, degraded, output)\n",
    "        \n",
    "        # Architecture comparison for the first image\n",
    "        if file == sorted(f for f in os.listdir('images') if f.lower().endswith('.bmp'))[0]:\n",
    "            compare_architectures(os.path.join('images', file))\n",
    "        \n",
    "        # Save output\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        out_path = os.path.join('output', f\"{base_name}_output.png\")\n",
    "        cv2.imwrite(out_path, cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "        print(f\"Saved to: {out_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {str(e)}\")\n",
    "\n",
    "# Generate final quality report\n",
    "if all_scores:\n",
    "    generate_quality_report(image_names, all_scores)\n",
    "    print(\"\\nGenerated comprehensive quality report in output/quality_report.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main processing loop\n",
    "# os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# for file in sorted(f for f in os.listdir('images') if f.lower().endswith('.bmp')):\n",
    "#     try:\n",
    "#         ref, degraded, output, scores = predict(os.path.join('images', file), use_attention=False)\n",
    "        \n",
    "#         if ref is None or degraded is None or output is None:\n",
    "#             continue\n",
    "            \n",
    "#         # Display metrics in clean table format\n",
    "#         print(\"\\n{:<20} {:>10} {:>12} {:>12}\".format('', 'PSNR (dB)', 'MSE', 'SSIM'))\n",
    "#         print(\"-\" * 50)\n",
    "#         print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Degraded Image:', *scores[0]))\n",
    "#         print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Reconstructed Image:', *scores[1]))\n",
    "        \n",
    "#         # Display images\n",
    "#         fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "#         titles = ['Original', 'Degraded', 'SRCNN Output']\n",
    "#         images = [ref, degraded, output]\n",
    "        \n",
    "#         for ax, img, title in zip(axs, images, titles):\n",
    "#             ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#             ax.set_title(title)\n",
    "#             ax.set_xticks([])\n",
    "#             ax.set_yticks([])\n",
    "        \n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Save output\n",
    "#         base_name = os.path.splitext(file)[0]\n",
    "#         out_path = os.path.join('output', f\"{base_name}_output.png\")\n",
    "#         plt.savefig(out_path, bbox_inches='tight', dpi=150)\n",
    "#         plt.close()\n",
    "#         print(f\"Saved to: {out_path}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {file}: {str(e)}\")\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing baboon.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           22.29       384.10       0.6734\n",
      "Reconstructed Image:      23.04       323.18       0.7675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a72c96272b14fd981b43a851114417e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/baboon_*.png\n",
      "\n",
      "Processing baby_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           34.26        24.38       0.9396\n",
      "Reconstructed Image:      36.27        15.36       0.9613\n",
      "\n",
      "Saved results to output/baby_GT_*.png\n",
      "\n",
      "Processing barbara.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           25.89       167.51       0.8183\n",
      "Reconstructed Image:      26.58       142.90       0.8684\n",
      "\n",
      "Saved results to output/barbara_*.png\n",
      "\n",
      "Processing bird_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           32.98        32.74       0.9593\n",
      "Reconstructed Image:      36.56        14.37       0.9846\n",
      "\n",
      "Saved results to output/bird_GT_*.png\n",
      "\n",
      "Processing bridge.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           25.95       165.27       0.7822\n",
      "Reconstructed Image:      27.47       116.32       0.8566\n",
      "\n",
      "Saved results to output/bridge_*.png\n",
      "\n",
      "Processing butterfly_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           24.74       218.17       0.8897\n",
      "Reconstructed Image:      30.37        59.67       0.9590\n",
      "\n",
      "Saved results to output/butterfly_GT_*.png\n",
      "\n",
      "Processing coastguard.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.37       119.19       0.7534\n",
      "Reconstructed Image:      28.68        88.15       0.8302\n",
      "\n",
      "Saved results to output/coastguard_*.png\n",
      "\n",
      "Processing comic.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           23.65       280.80       0.8325\n",
      "Reconstructed Image:      25.89       167.37       0.9110\n",
      "\n",
      "Saved results to output/comic_*.png\n",
      "\n",
      "Processing face.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.89        52.96       0.8421\n",
      "Reconstructed Image:      31.65        44.46       0.8737\n",
      "\n",
      "Saved results to output/face_*.png\n",
      "\n",
      "Processing flowers.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.25       122.36       0.8747\n",
      "Reconstructed Image:      29.67        70.22       0.9300\n",
      "\n",
      "Saved results to output/flowers_*.png\n",
      "\n",
      "Processing foreman.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           32.02        40.86       0.9390\n",
      "Reconstructed Image:      36.08        16.05       0.9653\n",
      "\n",
      "Saved results to output/foreman_*.png\n",
      "\n",
      "Processing head_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.92        52.56       0.8424\n",
      "Reconstructed Image:      31.68        44.16       0.8738\n",
      "\n",
      "Saved results to output/head_GT_*.png\n",
      "\n",
      "Processing lenna.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           31.36        47.50       0.8891\n",
      "Reconstructed Image:      33.11        31.76       0.9171\n",
      "\n",
      "Saved results to output/lenna_*.png\n",
      "\n",
      "Processing man.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.15       125.41       0.8208\n",
      "Reconstructed Image:      29.20        78.10       0.8768\n",
      "\n",
      "Saved results to output/man_*.png\n",
      "\n",
      "Processing monarch.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.05        64.29       0.9466\n",
      "Reconstructed Image:      35.14        19.92       0.9712\n",
      "\n",
      "Saved results to output/monarch_*.png\n",
      "\n",
      "Processing pepper.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           31.45        46.57       0.8881\n",
      "Reconstructed Image:      32.78        34.25       0.9086\n",
      "\n",
      "Saved results to output/pepper_*.png\n",
      "\n",
      "Processing ppt3.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           24.66       222.32       0.9296\n",
      "Reconstructed Image:      27.15       125.30       0.9561\n",
      "\n",
      "Saved results to output/ppt3_*.png\n",
      "\n",
      "Processing woman_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           29.37        75.11       0.9349\n",
      "Reconstructed Image:      33.63        28.18       0.9677\n",
      "\n",
      "Saved results to output/woman_GT_*.png\n",
      "\n",
      "Processing zebra.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.78       108.36       0.8896\n",
      "Reconstructed Image:      30.41        59.16       0.9324\n",
      "\n",
      "Saved results to output/zebra_*.png\n",
      "\n",
      "============================================================\n",
      "SUMMARY REPORT\n",
      "============================================================\n",
      "Processed 19 images successfully\n",
      "Average PSNR Improvement: 2.39 dB\n",
      "Average MSE Reduction: 45.87\n",
      "Average SSIM Improvement: 0.0456\n",
      "\n",
      "Full metrics saved to:\n",
      "- output/quality_metrics.csv\n",
      "- output/quality_report.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAvgPool2D, Dense, Multiply, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from ipywidgets import interact, IntSlider\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    \"\"\"Calculate image quality metrics\"\"\"\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    return [\n",
    "        psnr(img1, img2),\n",
    "        mse(img1, img2),\n",
    "        ssim(img1_gray, img2_gray, multichannel=True)\n",
    "    ]\n",
    "\n",
    "def attention_block(input_tensor):\n",
    "    \"\"\"Channel attention mechanism\"\"\"\n",
    "    channels = input_tensor.shape[-1]\n",
    "    gap = GlobalAvgPool2D()(input_tensor)\n",
    "    fc1 = Dense(channels//8, activation='relu')(gap)\n",
    "    fc2 = Dense(channels, activation='sigmoid')(fc1)\n",
    "    attention = Reshape((1, 1, channels))(fc2)\n",
    "    return Multiply()([input_tensor, attention])\n",
    "\n",
    "def build_model(with_attention=False):  # Default changed to False\n",
    "    \"\"\"Build SRCNN with optional attention\"\"\"\n",
    "    if with_attention:\n",
    "        inputs = tf.keras.Input(shape=(None, None, 1))\n",
    "        x = Conv2D(128, (9,9), activation='relu', padding='valid')(inputs)\n",
    "        x = attention_block(x)\n",
    "        x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "        outputs = Conv2D(1, (5,5), activation='linear', padding='valid')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Conv2D(128, (9,9), activation='relu', padding='valid', input_shape=(None, None, 1)),\n",
    "            Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "            Conv2D(1, (5,5), activation='linear', padding='valid')\n",
    "        ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0003),\n",
    "                loss='mean_squared_error',\n",
    "                metrics=['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "def modcrop(img, scale):\n",
    "    \"\"\"Crop image to make dimensions divisible by scale\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    h = h - h % scale\n",
    "    w = w - w % scale\n",
    "    return img[:h, :w]\n",
    "\n",
    "def shave(image, border):\n",
    "    \"\"\"Remove border pixels\"\"\"\n",
    "    return image[border:-border, border:-border]\n",
    "\n",
    "def predict(image_path, use_attention=False):\n",
    "    \"\"\"Super-resolve an image with error handling\"\"\"\n",
    "    try:\n",
    "        srcnn = build_model(with_attention=use_attention)\n",
    "        weights_path = '3051crop_weight_200.h5'\n",
    "        \n",
    "        if not os.path.exists(weights_path):\n",
    "            raise FileNotFoundError(f\"Weights file {weights_path} not found\")\n",
    "        \n",
    "        # Load weights with architecture mismatch handling\n",
    "        try:\n",
    "            srcnn.load_weights(weights_path)\n",
    "        except ValueError as e:\n",
    "            if \"Layer count mismatch\" in str(e):\n",
    "                print(\"\\n⚠️ Using basic model architecture to match weights file\")\n",
    "                srcnn = build_model(with_attention=False)\n",
    "                srcnn.load_weights(weights_path)\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "        degraded = cv2.imread(image_path)\n",
    "        if degraded is None:\n",
    "            raise ValueError(f\"Could not read image {image_path}\")\n",
    "            \n",
    "        ref_path = os.path.join('source', os.path.basename(image_path))\n",
    "        ref = cv2.imread(ref_path)\n",
    "        if ref is None:\n",
    "            raise ValueError(f\"Could not read reference image {ref_path}\")\n",
    "        \n",
    "        ref = modcrop(ref, 3)\n",
    "        degraded = modcrop(degraded, 3)\n",
    "        \n",
    "        ycrcb = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)\n",
    "        Y = np.zeros((1, *ycrcb.shape[:2], 1), dtype=np.float32)\n",
    "        Y[0, :, :, 0] = ycrcb[:, :, 0].astype(np.float32) / 255.0\n",
    "        \n",
    "        print(f\"\\nProcessing {os.path.basename(image_path)}\")\n",
    "        pre = srcnn.predict(Y, verbose=1)[0] * 255\n",
    "        pre = np.clip(pre, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        temp = shave(ycrcb, 6)\n",
    "        temp[:, :, 0] = pre[:, :, 0]\n",
    "        output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR)\n",
    "        \n",
    "        ref = shave(ref, 6)\n",
    "        degraded = shave(degraded, 6)\n",
    "        \n",
    "        return ref, degraded, output, [\n",
    "            compare_images(degraded, ref),\n",
    "            compare_images(output, ref)\n",
    "        ]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def interactive_comparison(original, degraded, enhanced):\n",
    "    \"\"\"Create interactive image comparison\"\"\"\n",
    "    def display_images(alpha=0.5):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(132)\n",
    "        plt.imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Degraded')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(133)\n",
    "        blended = cv2.addWeighted(degraded, 1-alpha, enhanced, alpha, 0)\n",
    "        plt.imshow(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Enhanced (Blend: {alpha:.1f})')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    interact(display_images, alpha=IntSlider(min=0, max=10, step=1, value=5))\n",
    "\n",
    "def generate_quality_report(image_names, all_scores):\n",
    "    \"\"\"Generate comprehensive quality report\"\"\"\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Image': image_names,\n",
    "        'PSNR_Degraded': [s[0][0] for s in all_scores],\n",
    "        'PSNR_Enhanced': [s[1][0] for s in all_scores],\n",
    "        'MSE_Degraded': [s[0][1] for s in all_scores],\n",
    "        'MSE_Enhanced': [s[1][1] for s in all_scores],\n",
    "        'SSIM_Degraded': [s[0][2] for s in all_scores],\n",
    "        'SSIM_Enhanced': [s[1][2] for s in all_scores]\n",
    "    })\n",
    "    \n",
    "    metrics_df['PSNR_Improvement'] = metrics_df['PSNR_Enhanced'] - metrics_df['PSNR_Degraded']\n",
    "    metrics_df['MSE_Reduction'] = metrics_df['MSE_Degraded'] - metrics_df['MSE_Enhanced']\n",
    "    metrics_df['SSIM_Improvement'] = metrics_df['SSIM_Enhanced'] - metrics_df['SSIM_Degraded']\n",
    "    \n",
    "    metrics_df.to_csv('output/quality_metrics.csv', index=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(231)\n",
    "    sns.barplot(x='Image', y='PSNR_Improvement', data=metrics_df)\n",
    "    plt.title('PSNR Improvement')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(232)\n",
    "    sns.barplot(x='Image', y='MSE_Reduction', data=metrics_df)\n",
    "    plt.title('MSE Reduction')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(233)\n",
    "    sns.barplot(x='Image', y='SSIM_Improvement', data=metrics_df)\n",
    "    plt.title('SSIM Improvement')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/quality_report.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Main processing loop\n",
    "os.makedirs('output', exist_ok=True)\n",
    "all_scores = []\n",
    "image_names = []\n",
    "\n",
    "for file in sorted(f for f in os.listdir('images') if f.lower().endswith('.bmp')):\n",
    "    try:\n",
    "        ref, degraded, output, scores = predict(os.path.join('images', file), use_attention=False)\n",
    "        \n",
    "        if ref is None or degraded is None or output is None:\n",
    "            continue\n",
    "            \n",
    "        all_scores.append(scores)\n",
    "        image_names.append(os.path.splitext(file)[0])\n",
    "            \n",
    "        print(\"\\n{:<20} {:>10} {:>12} {:>12}\".format('', 'PSNR (dB)', 'MSE', 'SSIM'))\n",
    "        print(\"-\" * 50)\n",
    "        print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Degraded Image:', *scores[0]))\n",
    "        print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Reconstructed Image:', *scores[1]))\n",
    "        \n",
    "        # Show interactive comparison for first image only\n",
    "        # if file == sorted(f for f in os.listdir('images') if f.lower().endswith('.bmp'))[0]:\n",
    "        interactive_comparison(ref, degraded, output)\n",
    "        \n",
    "        # Save output images\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        cv2.imwrite(f'output/{base_name}_original.png', cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))\n",
    "        cv2.imwrite(f'output/{base_name}_degraded.png', cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
    "        cv2.imwrite(f'output/{base_name}_reconstructed.png', cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "        print(f\"\\nSaved results to output/{base_name}_*.png\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file}: {str(e)}\")\n",
    "\n",
    "# Generate final report if we processed any images\n",
    "if all_scores:\n",
    "    report = generate_quality_report(image_names, all_scores)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Processed {len(image_names)} images successfully\")\n",
    "    print(f\"Average PSNR Improvement: {report['PSNR_Improvement'].mean():.2f} dB\")\n",
    "    print(f\"Average MSE Reduction: {report['MSE_Reduction'].mean():.2f}\")\n",
    "    print(f\"Average SSIM Improvement: {report['SSIM_Improvement'].mean():.4f}\")\n",
    "    print(\"\\nFull metrics saved to:\")\n",
    "    print(\"- output/quality_metrics.csv\")\n",
    "    print(\"- output/quality_report.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing baboon.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           22.29       384.10       0.6734\n",
      "Reconstructed Image:      23.04       323.18       0.7675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d54fc4003a145ba8841dee84695b7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/baboon_*.png\n",
      "\n",
      "Processing baby_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           34.26        24.38       0.9396\n",
      "Reconstructed Image:      36.27        15.36       0.9613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf678fda645f458680f4dcc1e29ebe21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/baby_GT_*.png\n",
      "\n",
      "Processing barbara.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           25.89       167.51       0.8183\n",
      "Reconstructed Image:      26.58       142.90       0.8684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea047eba0b0845d483f897131eb0dcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/barbara_*.png\n",
      "\n",
      "Processing bird_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           32.98        32.74       0.9593\n",
      "Reconstructed Image:      36.56        14.37       0.9846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086b7e6471bd4117aa86c82201d1e6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/bird_GT_*.png\n",
      "\n",
      "Processing bridge.bmp\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x16c8af420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           25.95       165.27       0.7822\n",
      "Reconstructed Image:      27.47       116.32       0.8566\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86637aa2f58342a8ae9ba6b5b02733b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/bridge_*.png\n",
      "\n",
      "Processing butterfly_GT.bmp\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x16c8751c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           24.74       218.17       0.8897\n",
      "Reconstructed Image:      30.37        59.67       0.9590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9460bf07aa9748edb8dbbd152d73ed76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/butterfly_GT_*.png\n",
      "\n",
      "Processing coastguard.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.37       119.19       0.7534\n",
      "Reconstructed Image:      28.68        88.15       0.8302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92f0d316f9049ea94ba57ac9d02b63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/coastguard_*.png\n",
      "\n",
      "Processing comic.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           23.65       280.80       0.8325\n",
      "Reconstructed Image:      25.89       167.37       0.9110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fb8ddb4c44429e91766caf4b2e86a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/comic_*.png\n",
      "\n",
      "Processing face.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.89        52.96       0.8421\n",
      "Reconstructed Image:      31.65        44.46       0.8737\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77d17d8a241463db53343c69f9bf055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/face_*.png\n",
      "\n",
      "Processing flowers.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.25       122.36       0.8747\n",
      "Reconstructed Image:      29.67        70.22       0.9300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a32d5387e474028aabcf530e72317cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/flowers_*.png\n",
      "\n",
      "Processing foreman.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           32.02        40.86       0.9390\n",
      "Reconstructed Image:      36.08        16.05       0.9653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a520104b53424ca9bd96a31abd998902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/foreman_*.png\n",
      "\n",
      "Processing head_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.92        52.56       0.8424\n",
      "Reconstructed Image:      31.68        44.16       0.8738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c532180f91a4a97a99288649cf43321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/head_GT_*.png\n",
      "\n",
      "Processing lenna.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           31.36        47.50       0.8891\n",
      "Reconstructed Image:      33.11        31.76       0.9171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df56e83f7f7f4e5cbb8b8655e9c46075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/lenna_*.png\n",
      "\n",
      "Processing man.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.15       125.41       0.8208\n",
      "Reconstructed Image:      29.20        78.10       0.8768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f3ba7c01fd4b8f91eef59e70d536c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/man_*.png\n",
      "\n",
      "Processing monarch.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.05        64.29       0.9466\n",
      "Reconstructed Image:      35.14        19.92       0.9712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe1edfe2ad6480a9f872e6badf37c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/monarch_*.png\n",
      "\n",
      "Processing pepper.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           31.45        46.57       0.8881\n",
      "Reconstructed Image:      32.78        34.25       0.9086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50cbaa458554726a4746c2ac3140b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/pepper_*.png\n",
      "\n",
      "Processing ppt3.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           24.66       222.32       0.9296\n",
      "Reconstructed Image:      27.15       125.30       0.9561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c493adcccf9547d281e57c2ade590f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/ppt3_*.png\n",
      "\n",
      "Processing woman_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           29.37        75.11       0.9349\n",
      "Reconstructed Image:      33.63        28.18       0.9677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c344fa5fca0545fe9d9a6d872b664904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/woman_GT_*.png\n",
      "\n",
      "Processing zebra.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.78       108.36       0.8896\n",
      "Reconstructed Image:      30.41        59.16       0.9324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5eaac057304dd9b2fea26b55a3b835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/zebra_*.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAvgPool2D, Dense, Multiply, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from ipywidgets import interact, IntSlider\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    \"\"\"Calculate image quality metrics\"\"\"\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)  # Use RGB instead of BGR\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    return [\n",
    "        psnr(img1, img2),\n",
    "        mse(img1, img2),\n",
    "        ssim(img1_gray, img2_gray, multichannel=True)\n",
    "    ]\n",
    "\n",
    "def attention_block(input_tensor):\n",
    "    \"\"\"Channel attention mechanism\"\"\"\n",
    "    channels = input_tensor.shape[-1]\n",
    "    gap = GlobalAvgPool2D()(input_tensor)\n",
    "    fc1 = Dense(channels//8, activation='relu')(gap)\n",
    "    fc2 = Dense(channels, activation='sigmoid')(fc1)\n",
    "    attention = Reshape((1, 1, channels))(fc2)\n",
    "    return Multiply()([input_tensor, attention])\n",
    "\n",
    "def build_model(with_attention=False):\n",
    "    \"\"\"Build SRCNN with optional attention\"\"\"\n",
    "    if with_attention:\n",
    "        inputs = tf.keras.Input(shape=(None, None, 1))\n",
    "        x = Conv2D(128, (9,9), activation='relu', padding='valid')(inputs)\n",
    "        x = attention_block(x)\n",
    "        x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "        outputs = Conv2D(1, (5,5), activation='linear', padding='valid')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Conv2D(128, (9,9), activation='relu', padding='valid', input_shape=(None, None, 1)),\n",
    "            Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "            Conv2D(1, (5,5), activation='linear', padding='valid')\n",
    "        ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0003),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "def modcrop(img, scale):\n",
    "    \"\"\"Crop image to make dimensions divisible by scale\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    h = h - h % scale\n",
    "    w = w - w % scale\n",
    "    return img[:h, :w]\n",
    "\n",
    "def shave(image, border):\n",
    "    \"\"\"Remove border pixels\"\"\"\n",
    "    return image[border:-border, border:-border]\n",
    "\n",
    "def predict(image_path, use_attention=False):\n",
    "    \"\"\"Super-resolve an image with error handling\"\"\"\n",
    "    try:\n",
    "        srcnn = build_model(with_attention=use_attention)\n",
    "        weights_path = '3051crop_weight_200.h5'\n",
    "        \n",
    "        if not os.path.exists(weights_path):\n",
    "            raise FileNotFoundError(f\"Weights file {weights_path} not found\")\n",
    "        \n",
    "        # Load weights with architecture mismatch handling\n",
    "        try:\n",
    "            srcnn.load_weights(weights_path)\n",
    "        except ValueError as e:\n",
    "            if \"Layer count mismatch\" in str(e):\n",
    "                print(\"\\n⚠️ Using basic model architecture to match weights file\")\n",
    "                srcnn = build_model(with_attention=False)\n",
    "                srcnn.load_weights(weights_path)\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "        degraded = cv2.imread(image_path)[..., ::-1]  # Convert BGR to RGB\n",
    "        if degraded is None:\n",
    "            raise ValueError(f\"Could not read image {image_path}\")\n",
    "            \n",
    "        ref_path = os.path.join('source', os.path.basename(image_path))\n",
    "        ref = cv2.imread(ref_path)[..., ::-1]  # Convert BGR to RGB\n",
    "        if ref is None:\n",
    "            raise ValueError(f\"Could not read reference image {ref_path}\")\n",
    "        \n",
    "        ref = modcrop(ref, 3)\n",
    "        degraded = modcrop(degraded, 3)\n",
    "        \n",
    "        ycrcb = cv2.cvtColor(degraded, cv2.COLOR_RGB2YCrCb)\n",
    "        Y = np.zeros((1, *ycrcb.shape[:2], 1), dtype=np.float32)\n",
    "        Y[0, :, :, 0] = ycrcb[:, :, 0].astype(np.float32) / 255.0\n",
    "        \n",
    "        print(f\"\\nProcessing {os.path.basename(image_path)}\")\n",
    "        pre = srcnn.predict(Y, verbose=1)[0] * 255\n",
    "        pre = np.clip(pre, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        temp = shave(ycrcb, 6)\n",
    "        temp[:, :, 0] = pre[:, :, 0]\n",
    "        output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2RGB)\n",
    "        \n",
    "        ref = shave(ref, 6)\n",
    "        degraded = shave(degraded, 6)\n",
    "        \n",
    "        return ref, degraded, output, [\n",
    "            compare_images(degraded, ref),\n",
    "            compare_images(output, ref)\n",
    "        ]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def interactive_comparison(original, degraded, enhanced):\n",
    "    \"\"\"Create interactive image comparison\"\"\"\n",
    "    def display_images(alpha=0.5):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(original)  # No need to convert, it's already RGB\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(132)\n",
    "        plt.imshow(degraded)\n",
    "        plt.title('Degraded')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(133)\n",
    "        blended = cv2.addWeighted(degraded, 1-alpha, enhanced, alpha, 0)\n",
    "        plt.imshow(blended)\n",
    "        plt.title(f'Enhanced (Blend: {alpha:.1f})')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    interact(display_images, alpha=IntSlider(min=0, max=10, step=1, value=5))\n",
    "\n",
    "# Main processing loop\n",
    "os.makedirs('output', exist_ok=True)\n",
    "all_scores = []\n",
    "image_names = []\n",
    "\n",
    "for file in sorted(f for f in os.listdir('images') if f.lower().endswith('.bmp')):\n",
    "    try:\n",
    "        ref, degraded, output, scores = predict(os.path.join('images', file), use_attention=False)\n",
    "        \n",
    "        if ref is None or degraded is None or output is None:\n",
    "            continue\n",
    "            \n",
    "        all_scores.append(scores)\n",
    "        image_names.append(os.path.splitext(file)[0])\n",
    "            \n",
    "        print(\"\\n{:<20} {:>10} {:>12} {:>12}\".format('', 'PSNR (dB)', 'MSE', 'SSIM'))\n",
    "        print(\"-\" * 50)\n",
    "        print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Degraded Image:', *scores[0]))\n",
    "        print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Reconstructed Image:', *scores[1]))\n",
    "        \n",
    "        interactive_comparison(ref, degraded, output)\n",
    "        \n",
    "        # Save output images correctly\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        cv2.imwrite(f'output/{base_name}_original.png', ref)\n",
    "        cv2.imwrite(f'output/{base_name}_degraded.png', degraded)\n",
    "        cv2.imwrite(f'output/{base_name}_reconstructed.png', output)\n",
    "        print(f\"\\nSaved results to output/{base_name}_*.png\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing baboon.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           22.29       384.10       0.6734\n",
      "Reconstructed Image:      23.04       323.18       0.7675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c17db79f63427897ee954efcbe98a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/baboon_*.png\n",
      "\n",
      "Processing baby_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           34.26        24.38       0.9396\n",
      "Reconstructed Image:      36.27        15.36       0.9613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acb0bf0f0cd4f85a812810db9e6a99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/baby_GT_*.png\n",
      "\n",
      "Processing barbara.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           25.89       167.51       0.8183\n",
      "Reconstructed Image:      26.58       142.90       0.8684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf8814bd67d4033b77c6716e9470ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/barbara_*.png\n",
      "\n",
      "Processing bird_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           32.98        32.74       0.9593\n",
      "Reconstructed Image:      36.56        14.37       0.9846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd4362de9cf4215bb4f3e85d6049ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/bird_GT_*.png\n",
      "\n",
      "Processing bridge.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           25.95       165.27       0.7822\n",
      "Reconstructed Image:      27.47       116.32       0.8566\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d15545d07404a599cf97cba52670b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/bridge_*.png\n",
      "\n",
      "Processing butterfly_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           24.74       218.17       0.8897\n",
      "Reconstructed Image:      30.37        59.67       0.9590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8668faaac232486da44f8e41abaf7242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/butterfly_GT_*.png\n",
      "\n",
      "Processing coastguard.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.37       119.19       0.7534\n",
      "Reconstructed Image:      28.68        88.15       0.8302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428aad13ef0341f8b1b5eac38d53a293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/coastguard_*.png\n",
      "\n",
      "Processing comic.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           23.65       280.80       0.8325\n",
      "Reconstructed Image:      25.89       167.37       0.9110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4b9e7f2219435db385d2cb8c054f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/comic_*.png\n",
      "\n",
      "Processing face.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.89        52.96       0.8421\n",
      "Reconstructed Image:      31.65        44.46       0.8737\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f02e81fc6e740fb818518764d4dadb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/face_*.png\n",
      "\n",
      "Processing flowers.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.25       122.36       0.8747\n",
      "Reconstructed Image:      29.67        70.22       0.9300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7761dd78504b2f9110060967813c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/flowers_*.png\n",
      "\n",
      "Processing foreman.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           32.02        40.86       0.9390\n",
      "Reconstructed Image:      36.08        16.05       0.9653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77350607c69e40d6a7b2016fc8329d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/foreman_*.png\n",
      "\n",
      "Processing head_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.92        52.56       0.8424\n",
      "Reconstructed Image:      31.68        44.16       0.8738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3928376b9b3408d80c6f4d9e93c366b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/head_GT_*.png\n",
      "\n",
      "Processing lenna.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           31.36        47.50       0.8891\n",
      "Reconstructed Image:      33.11        31.76       0.9171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee6aed223d447bc8787ed467f4713e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/lenna_*.png\n",
      "\n",
      "Processing man.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.15       125.41       0.8208\n",
      "Reconstructed Image:      29.20        78.10       0.8768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f20f4701792453091a3fe257c57efd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/man_*.png\n",
      "\n",
      "Processing monarch.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           30.05        64.29       0.9466\n",
      "Reconstructed Image:      35.14        19.92       0.9712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab5f5a8eabe417cb0bc16c8a1c23496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/monarch_*.png\n",
      "\n",
      "Processing pepper.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           31.45        46.57       0.8881\n",
      "Reconstructed Image:      32.78        34.25       0.9086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9c4d0d69634aba9693d03c7f7d59bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/pepper_*.png\n",
      "\n",
      "Processing ppt3.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           24.66       222.32       0.9296\n",
      "Reconstructed Image:      27.15       125.30       0.9561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cbbb8e4e4b40769fd679ac53ac3d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/ppt3_*.png\n",
      "\n",
      "Processing woman_GT.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           29.37        75.11       0.9349\n",
      "Reconstructed Image:      33.63        28.18       0.9677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad71751852734589a887b79890a2734a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/woman_GT_*.png\n",
      "\n",
      "Processing zebra.bmp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "\n",
      "                      PSNR (dB)          MSE         SSIM\n",
      "--------------------------------------------------\n",
      "Degraded Image:           27.78       108.36       0.8896\n",
      "Reconstructed Image:      30.41        59.16       0.9324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b94b580092475b8e4bb56357a1e45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='alpha', max=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results to output/zebra_*.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAvgPool2D, Dense, Multiply, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from ipywidgets import interact, IntSlider\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    \"\"\"Calculate image quality metrics\"\"\"\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)  # Use RGB instead of BGR\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    return [\n",
    "        psnr(img1, img2),\n",
    "        mse(img1, img2),\n",
    "        ssim(img1_gray, img2_gray, multichannel=True)\n",
    "    ]\n",
    "\n",
    "def attention_block(input_tensor):\n",
    "    \"\"\"Channel attention mechanism\"\"\"\n",
    "    channels = input_tensor.shape[-1]\n",
    "    gap = GlobalAvgPool2D()(input_tensor)\n",
    "    fc1 = Dense(channels//8, activation='relu')(gap)\n",
    "    fc2 = Dense(channels, activation='sigmoid')(fc1)\n",
    "    attention = Reshape((1, 1, channels))(fc2)\n",
    "    return Multiply()([input_tensor, attention])\n",
    "\n",
    "def build_model(with_attention=True):\n",
    "    \"\"\"Build SRCNN with optional attention\"\"\"\n",
    "    if with_attention:\n",
    "        inputs = tf.keras.Input(shape=(None, None, 1))\n",
    "        x = Conv2D(128, (9,9), activation='relu', padding='valid')(inputs)\n",
    "        x = attention_block(x)\n",
    "        x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "        outputs = Conv2D(1, (5,5), activation='linear', padding='valid')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Conv2D(128, (9,9), activation='relu', padding='valid', input_shape=(None, None, 1)),\n",
    "            Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "            Conv2D(1, (5,5), activation='linear', padding='valid')\n",
    "        ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0003),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "def modcrop(img, scale):\n",
    "    \"\"\"Crop image to make dimensions divisible by scale\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    h = h - h % scale\n",
    "    w = w - w % scale\n",
    "    return img[:h, :w]\n",
    "\n",
    "def shave(image, border):\n",
    "    \"\"\"Remove border pixels\"\"\"\n",
    "    return image[border:-border, border:-border]\n",
    "\n",
    "def predict(image_path, use_attention=True):\n",
    "    \"\"\"Super-resolve an image with error handling\"\"\"\n",
    "    try:\n",
    "        srcnn = build_model(with_attention=use_attention)\n",
    "        weights_path = '3051crop_weight_200.h5'\n",
    "        \n",
    "        if not os.path.exists(weights_path):\n",
    "            raise FileNotFoundError(f\"Weights file {weights_path} not found\")\n",
    "        \n",
    "        # Load weights with architecture mismatch handling\n",
    "        try:\n",
    "            srcnn.load_weights(weights_path)\n",
    "        except ValueError as e:\n",
    "            if \"Layer count mismatch\" in str(e):\n",
    "                print(\"\\n⚠️ Using basic model architecture to match weights file\")\n",
    "                srcnn = build_model(with_attention=False)\n",
    "                srcnn.load_weights(weights_path)\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "        degraded = cv2.imread(image_path)[..., ::-1]  # Convert BGR to RGB\n",
    "        if degraded is None:\n",
    "            raise ValueError(f\"Could not read image {image_path}\")\n",
    "            \n",
    "        ref_path = os.path.join('source', os.path.basename(image_path))\n",
    "        ref = cv2.imread(ref_path)[..., ::-1]  # Convert BGR to RGB\n",
    "        if ref is None:\n",
    "            raise ValueError(f\"Could not read reference image {ref_path}\")\n",
    "        \n",
    "        ref = modcrop(ref, 3)\n",
    "        degraded = modcrop(degraded, 3)\n",
    "        \n",
    "        ycrcb = cv2.cvtColor(degraded, cv2.COLOR_RGB2YCrCb)\n",
    "        Y = np.zeros((1, *ycrcb.shape[:2], 1), dtype=np.float32)\n",
    "        Y[0, :, :, 0] = ycrcb[:, :, 0].astype(np.float32) / 255.0\n",
    "        \n",
    "        print(f\"\\nProcessing {os.path.basename(image_path)}\")\n",
    "        pre = srcnn.predict(Y, verbose=1)[0] * 255\n",
    "        pre = np.clip(pre, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        temp = shave(ycrcb, 6)\n",
    "        temp[:, :, 0] = pre[:, :, 0]\n",
    "        output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2RGB)\n",
    "        \n",
    "        ref = shave(ref, 6)\n",
    "        degraded = shave(degraded, 6)\n",
    "        \n",
    "        return ref, degraded, output, [\n",
    "            compare_images(degraded, ref),\n",
    "            compare_images(output, ref)\n",
    "        ]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def interactive_comparison(original, degraded, enhanced):\n",
    "    \"\"\"Create interactive image comparison\"\"\"\n",
    "    def display_images(alpha=0.5):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(original)  # No need to convert, it's already RGB\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(132)\n",
    "        plt.imshow(degraded)\n",
    "        plt.title('Degraded')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(133)\n",
    "        blended = cv2.addWeighted(degraded, 1-alpha, enhanced, alpha, 0)\n",
    "        plt.imshow(blended)\n",
    "        plt.title(f'Enhanced (Blend: {alpha:.1f})')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    interact(display_images, alpha=IntSlider(min=0, max=10, step=1, value=5))\n",
    "\n",
    "# Main processing loop\n",
    "os.makedirs('output', exist_ok=True)\n",
    "all_scores = []\n",
    "image_names = []\n",
    "\n",
    "for file in sorted(f for f in os.listdir('images') if f.lower().endswith('.bmp')):\n",
    "    try:\n",
    "        ref, degraded, output, scores = predict(os.path.join('images', file), use_attention=False)\n",
    "        \n",
    "        if ref is None or degraded is None or output is None:\n",
    "            continue\n",
    "            \n",
    "        all_scores.append(scores)\n",
    "        image_names.append(os.path.splitext(file)[0])\n",
    "            \n",
    "        print(\"\\n{:<20} {:>10} {:>12} {:>12}\".format('', 'PSNR (dB)', 'MSE', 'SSIM'))\n",
    "        print(\"-\" * 50)\n",
    "        print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Degraded Image:', *scores[0]))\n",
    "        print(\"{:<20} {:>10.2f} {:>12.2f} {:>12.4f}\".format('Reconstructed Image:', *scores[1]))\n",
    "        \n",
    "        interactive_comparison(ref, degraded, output)\n",
    "        \n",
    "        # Save output images correctly\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        cv2.imwrite(f'output/{base_name}_original.png', ref)\n",
    "        cv2.imwrite(f'output/{base_name}_degraded.png', degraded)\n",
    "        cv2.imwrite(f'output/{base_name}_reconstructed.png', output)\n",
    "        print(f\"\\nSaved results to output/{base_name}_*.png\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file}: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
